{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Régression linéaire et gradient stochastique\n",
    "\n",
    "Ce TD-TP a pour objectif de plonger de manière un peu plus individualisée dans le cours d’optimisation stochastique. Il n’est pas noté, mais j’encourage très vivement les étudiants à rédiger consciencieusement leurs réponses et leurs idées. La rédaction force à mieux présenter les choses et surtout à mieux les cerner. Ca me permettra aussi plus facilement de corriger d’éventuelles incompréhensions.\n",
    "\n",
    "## 1. Introduction\n",
    "\n",
    "L’objectif de ce TP est d’illustrer la première partie du cours d’optimisation stochastique sur les erreurs en apprentissage et d’implémenter les premières versions du gradient stochastique. Il a aussi pour objectif de vous entraîner à effectuer des calculs avec des variables aléatoires pour les rendre plus accessibles et mieux comprendre les cours à venir.\n",
    "\n",
    "Nous allons nous placer dans le cadre de travail le plus simple : la régression linéaire. Ce cadre présente plusieurs avantages :\n",
    "- C’est probablement le plus simple d’un point de vue théorique et il permet d’appréhender de nombreux phénomènes avec des mathématiques relativement élémentaires.\n",
    "\n",
    "- C’est probablement encore le plus utilisé dans les applications, et il me semble nécessaire de le comprendre profondément."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Le cadre\n",
    "Soit $X$ un vecteur aléatoire de $\\mathbb{R}^d$, pour $d \\in \\mathbb{N}$ suivant une certaine distribution de probabilité inconnue $P_X$. Pour un certain vecteur $\\theta \\in \\mathbb{R}^d$, on construit une variable aléatoire $Y \\in \\mathbb{R}$ définie par :\n",
    "$$\n",
    "Y = \\langle \\theta, X\\rangle + B \\quad \\text{ où } \\quad B \\sim \\mathcal{N}(0, \\sigma^2) \\text{ est une variable aléatoire gaussienne indépendante de } X.\n",
    "$$\n",
    "\n",
    "> L’objectif de ce TP est d’apprendre le vecteur $\\theta$ inconnu à partir de $n \\in \\mathbb{N}$ observations $(x_i, y_i)_{1 \\leq i \\leq n}$ tirées indépendamment suivant la loi $P$.\n",
    "\n",
    "Pour ce faire, on peut simplement résoudre le problème de minimisation du risque empirique suivant :\n",
    "\n",
    "\\begin{equation}\n",
    "    \\underset{\\omega \\in \\mathbb{R}^d}{inf} E_n(\\omega) = \\frac{1}{2n} \\sum_{i = 1}^{n} (\\langle \\omega, x_i \\rangle - y_i)^2\n",
    "\\end{equation}\n",
    "\n",
    "On notera $\\omega_n^*$ n’importe quel minimiseur (sous réserve d’existence) du problème ci-dessus.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Questions préliminaires\n",
    "Ces questions introductives sont posées pour se forcer à revoir un peu le cours et les notions introduites.\n",
    "\n",
    "1. Déterminer les espaces $\\mathcal{X}$ et $\\mathcal{Y}$ du cours. Quelle est la fonction perte $l$ utilisée ici ? Quelle est la famille $\\mathcal{H}$ de prédicteurs utilisés ?\n",
    "\n",
    "2. Déterminer la loi conditionnelle $P(Y | X)$.\n",
    "\n",
    "3. Quelle est la définition du risque moyen ici ?\n",
    "\n",
    "4. Quel est le prédicteur optimal $\\omega^*$ ? Est-il unique ? Que vaut $E(\\omega^*)$ ?\n",
    "\n",
    "5. Si $X \\sim \\mathcal{N}(0, I_d)$ que vaut $E(\\omega)$ ?\n",
    "\n",
    "6. Déterminer l’erreur d’approximation $\\mathcal{E}_{app}$ pour ce problème.\n",
    "\n",
    "7. Est-ce que la fonction $E_n$ est convexe ou non convexe ?\n",
    "\n",
    "8. Calculer $\\nabla E_n(\\omega)$.\n",
    "\n",
    "9. Est-ce que le problème (1) possède une solution ? Une solution unique ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Erreur d’estimation\n",
    "Dans cette partie, on se propose de borner l’erreur d’estimation $\\mathcal{E}$\n",
    "$$\n",
    "\\mathcal{E}_{est} = E(\\omega_n^*) − E(\\omega^*),\n",
    "$$\n",
    "pour se faire une idée de la vitesse de convergence du risque empirique.\n",
    "\n",
    "Soient $(Z_i)_{1\\leq i \\leq n}$ un ensemble de variables aléatoires i.i.d. de variance $\\sigma^2$.\n",
    "1. Que vaut $Var(\\frac{1}{n} \\sum_{i = 1}^n Z_i)$ ?\n",
    "\n",
    "2. Que peut-on en déduire sur la différence $E_n(\\omega) − E(\\omega)$ ?\n",
    "\n",
    "\n",
    "Malheureusement, ce résultat est valable pour un vecteur $\\omega \\in \\mathbb{R}^d$ quelconque, mais ne permet pas de contrôler $E(\\omega_n^*) − E(\\omega^*)$ directement. On va donc affiner ce résultat. On suppose que les paramètres optimaux $\\omega^*$ et $\\omega_n^*$ vivent dans une boule de rayon $R > 0$. On utilise la décomposition suivante :\n",
    "\n",
    "$$\n",
    "\\mathcal{E}_{est} = [ E(\\omega_n^*) - E_n(\\omega_n^*)] + [ E_n(\\omega_n^*) - E_n(\\omega^*)] + [ E_n(\\omega^*) - E(\\omega^*)].\n",
    "$$\n",
    "\n",
    "1. Que pouvez-vous dire de $E_n(\\omega_n^*) - E_n(\\omega^*)$ ?\n",
    "\n",
    "2. En déduire que : $\\quad \\quad \\mathcal{E}_{est} \\leq 2 \\underset{||\\omega||_2 \\leq R}{ sup } |E(\\omega) - E_n(\\omega)|.$\n",
    "\n",
    "3. Etablir l’identité suivante :\n",
    "\n",
    "\\begin{align*}\n",
    "    E_n(\\omega) - E(\\omega) &= \\frac{1}{2} \\langle \\omega, (\\frac{1}{n} \\sum_{i = 1}^{n} x_i x_i^T - \\mathbb{E}(XX^T))\\omega \\rangle \\\\\n",
    "    &- \\langle \\omega^T, (\\frac{1}{n} \\sum_{i = 1}^{n} y_i x_i^T - \\mathbb{E}(YX)) \\rangle\\\\\n",
    "    &+ \\frac{1}{2} (\\frac{1}{n} \\sum_{i = 1}^{n} y_i^2 - \\mathbb{E}(Y^2)).\n",
    "\\end{align*}\n",
    "\n",
    "4. Borner la valeur absolue des erreurs ci-dessus en espérance. Vous pourrez par exemple utiliser des inégalités de Bernstein (scalaires, vectorielles et matricielles). Que conclure sur le taux de convergence de $\\mathcal{E}_{est}$ vers $0$ ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Questions d’optimisation stochastique\n",
    "Dans cette partie, on suppose que $i_k$ est un indice aléatoire tiré uniformément dans l’ensemble $\\{1, \\dots , n\\}$.\n",
    "\n",
    "1. Est-ce que $E_n$ est fortement convexe ?\n",
    "\n",
    "2. Soit $f_i(\\omega) = \\frac{1}{2}||\\langle \\omega, x_i \\rangle − y_i||_2^2$. Calculer $\\nabla f_i(\\omega)$.\n",
    "\n",
    "3. Calculer $\\mathbb{E}_{i_k} (\\nabla f_{i_k} (\\omega))$.\n",
    "\n",
    "4. Calculer la constante de Lipschitz $L$ de $\\nabla E_n(\\omega)$.\n",
    "\n",
    "5. Calculer $\\mathbb{E}_{i_k} (||\\nabla f_{i_k} (\\omega)||_2^2)$ en fonction de $||\\nabla E_n(\\omega)||_2^2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Travail pratique (théorie)\n",
    "Dans ce travail nous supposerons simplement que $X \\sim \\mathcal{N}(0, I_d)$. Nous supposons aussi que $\\theta_i = 1$ pour tout $i$.\n",
    "\n",
    "1. Définir une fonction \\\n",
    "$\\texttt{X, Y = generate\\_data(d,n,theta,sigma)}$\n",
    "\n",
    "2. Définir une fonction qui renvoit le risque moyen \\\n",
    "$\\texttt{E(w,theta,sigma)}$\n",
    "\n",
    "3. Définir une fonction qui renvoit le risque empirique \\\n",
    "$\\texttt{En(w,X,Y)}$\n",
    "\n",
    "4. Définir une fonction qui renvoit le gradient du risque empirique \\\n",
    "$\\texttt{grad\\_En(w,X,Y)}$\n",
    "\n",
    "5. Définir une fonction qui renvoit le gradient stochastique suivant la loi uniforme \\\n",
    "$\\texttt{grad\\_sto\\_En(w,X,Y,n\\_batch)}$\n",
    "\n",
    "6. Calculer la constante de Lipschitz de $\\nabla E_n$ numériquement.\n",
    "\n",
    "7. Si vous aviez un choix, quelle méthode d’optimisation vous semblerait la plus efficace pour minimiser $E_n$ ?\n",
    "\n",
    "8. Effectuer une descente de gradient à pas constant sur $E_n$ et stocker les suites $E_n(\\omega_k)$ et $E(\\omega_k)$.\n",
    "\n",
    "9. Etudier l’erreur d’approximation $||\\omega_n^* - \\theta ||_2^2$ en fonction de $n$. Expliquez vos observations à partir du cours et des questions théoriques.\n",
    "\n",
    "10. Effectuer un algorithme de gradient stochastique à pas constant sur $E_n$ et stocker les suites $E_n(\\omega_k)$ et $E(\\omega_k)$.\n",
    "\n",
    "11. Effectuer un algorithme de gradient stochastique à pas décroissant sur $E_n$ et stocker les suites $E_n(\\omega_k)$ et $E(\\omega_k)$.\n",
    "\n",
    "12. Comparer les taux de convergence pour le risque empirique et le risque moyen en fonction du nombre d’epoch pour chaque méthode.\n",
    "\n",
    "13. Implémenter un algorithme de gradient stochastique online et comparer aux précédents.\n",
    "\n",
    "14. Implémenter la méthode SAGA et comparer.\n",
    "\n",
    "15. Relier les observations au cours. Quelle méthode devrait être privilégiée ?\n",
    "\n",
    "16. Etudier l’influence de $n$, de $\\sigma$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Travail pratique (pratique)\n",
    "Pour finir ce TP, nous proposons de tester les algorithmes de gradient stochastique dans un cadre moderne, avec la librairie PyTorch et des réseaux de Neurones. De très nombreux tutoriels sur ces logiciels existent et sont bien réalisés.\n",
    "\n",
    "> Je vous propose ici de suivre le tutoriel suivant : [pytorch-mnist](https://nextjournal.com/gkoehler/pytorch-mnist).\n",
    "\n",
    "Une fois que vous avez réussi à reproduire les expériences suggérées, comparez différents algorithmes d’optimisation disponibles sous PyTorch (SGD simple, SGD Momentum, RMSProp, SAGA, ADAM)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. L’inégalité de Bernstein (inégalité de concentration)\n",
    "$\\textbf{Théorème 1 }$ (Inégalité de Bernstein). $\\textit{Soient } Z_1, \\dots , Z_n \\textit{ un ensemble de } n \\textit{ vecteurs aléatoires indépendants et identiquement distribués tels que } |Z_i| \\leq c \\textit{ presque sûrement, } \\mathbb{E}(Z_i) = \\mu \\textit{ et } Var(Z_i) = \\sigma^2 \\textit{. Alors : }$\n",
    "\n",
    "\\begin{equation}\n",
    "    \\mathbb{P}(|\\frac{1}{n}\\sum_{i = 1}^n Z_i - \\mu | \\geq t) \\leq 2 \\exp(\\frac{nt^2}{2 \\sigma^2 + 2 ct /3}).\n",
    "\\end{equation}\n",
    "\n",
    "Ce type d’inégalité est appelé inégalité de concentration. Il indique que la probabilité que la moyenne empirique dévie de la moyenne est très faible si on a un nombre d’observations suffisant.\n",
    "\n",
    "1. Etablir la proposition suivante : l’inégalité suivante est valide avec une probabilité supérieure à $1 − \\delta$.\n",
    "\n",
    "2. On aimerait montrer que $E_n$ est proche de $E$. Comment utiliser l’inégalité de Bernstein ou le corollaire précédent ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
