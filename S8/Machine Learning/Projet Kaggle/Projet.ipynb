{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle Project\n",
    "\n",
    "Deep learning models are widely used for image classification. The goal of this project is to compare state-of-the-art models on a subset of ImageNet dataset.\n",
    "\n",
    "The link of the project is : https://www.kaggle.com/competitions/modia-ml-2024/overview\n",
    "\n",
    "**Notice** : You should upload a report, together with your code to Moodle, for the validation of the course. Do not copy-paste other people’s report or code.\n",
    "\n",
    "**Due** : 27 Juin 2024."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Learn how to use Pytorch\n",
    "\n",
    "Refer to the website https://pytorch.org/tutorials/beginner/basics/intro.html."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Train state-of-the-art CNN models\n",
    "\n",
    "The goal is to achieve a good classification accuracy on the test dataset, using Pytorch.\n",
    "\n",
    " - Implement one or two models from the following list :\n",
    "    - LeNet Model [1]\n",
    "    - AlexNet Model [2]\n",
    "    - ResNet Model [3]\n",
    "\n",
    " - In your report, you should give a precise definition of the model which you use, e.g. the number of layers and the type of each layer in CNN.\n",
    "\n",
    " - Pre-process your images in black and white\n",
    "\n",
    " - Pre-process your images so that they have the same input size to your model, e.g. use data augmentation.\n",
    "\n",
    " - Train your model using mini-batch SGD. Specify the optimization method which you use and report the total training time. To reduce the training time, you may use a GPU card.\n",
    "\n",
    " - Perform your parameter turning on a validation set to avoid over-fitting. Summarize your results in table/figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, Subset\n",
    "from PIL import Image\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the dataset and preprocessing\n",
    "class CustomImageDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, labels_file, im_dir, transform=None):\n",
    "        self.img_labels = pd.read_csv(labels_file)\n",
    "        self.img_dir = im_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, str(self.img_labels.iloc[idx, 0]) + \".jpg\")\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        label = self.img_labels.iloc[idx, 1]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "# Image transformations\n",
    "IMAGE_SIZE = 256\n",
    "transform = transforms.Compose([\n",
    "    # Preprocess in black and white, and same size\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.CenterCrop(IMAGE_SIZE),\n",
    "    \n",
    "    # Data augmentation\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=0.5,std=0.5)\n",
    "])\n",
    "\n",
    "# Data paths\n",
    "label_path = './train.csv'\n",
    "train_dir = './train/'\n",
    "test_dir = './test/'\n",
    "\n",
    "# Dataset\n",
    "train_dataset = CustomImageDataset(labels_file=label_path, im_dir=train_dir, transform=transform)\n",
    "test_dataset = CustomImageDataset(labels_file=label_path, im_dir=test_dir, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création du modèle LeNet\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self, num_channels=1, num_classes=4):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(num_channels, 6, kernel_size=5, padding=2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)\n",
    "        self.fc1   = nn.Linear(62*62*16, 120)\n",
    "        self.fc2   = nn.Linear(120, 84)\n",
    "        self.fc3   = nn.Linear(84, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), kernel_size=(2, 2), stride=2)\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), kernel_size=(2, 2), stride=2)\n",
    "        x = nn.Flatten()(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "num_classes = 4\n",
    "num_epochs = 10\n",
    "batch_size = 128\n",
    "learning_rate = 0.01\n",
    "train_size = len(train_dataset)*0.8\n",
    "\n",
    "model = LeNet(num_classes=num_classes)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay = 0.001, momentum = 0.9)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5)\n",
    "\n",
    "# Data loader\n",
    "train_dataset, val_dataset = random_split(train_dataset, [int(train_size), len(train_dataset)-int(train_size)])\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function\n",
    "def train(model, criterion, optimizer):\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    \n",
    "    train_losses = []\n",
    "    train_acc = []\n",
    "    \n",
    "    with tqdm(total=len(train_loader), desc=\"Training\", unit=\"batch\") as pbar:\n",
    "        for i, (image, label) in enumerate(train_loader):\n",
    "            image = image.to(device)\n",
    "            label = label.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            output = model(image)\n",
    "            loss_value = criterion(output, label)\n",
    "            train_losses.append(loss_value)\n",
    "            \n",
    "            # Calculate softmax and accuracy\n",
    "            soft_output = torch.nn.functional.softmax(output, dim=1)\n",
    "            _, predicted = torch.max(soft_output, 1)\n",
    "            correct = (predicted == label).sum().item()\n",
    "            accuracy = correct / label.size(0)\n",
    "            train_acc.append(accuracy)\n",
    "\n",
    "            # Update progress bar\n",
    "            loss_cur = loss_value.item()\n",
    "            current = i * len(image) + len(image)\n",
    "            acc_cur = np.mean(train_acc)\n",
    "            pbar.set_postfix(loss=f\"{loss_cur:.7f}\", current=f\"{current}/{len(train_loader.dataset)}\", accuracy=f\"{acc_cur:.7f}\")\n",
    "\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss_value.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            pbar.update(1)\n",
    "\n",
    "    return np.mean(train_losses), np.mean(train_acc)\n",
    "\n",
    "\n",
    "    for images, labels in tqdm(train_loader):\n",
    "\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        train_losses.append(loss.item())\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "            \n",
    "        # Compute accuracy\n",
    "        _, argmax = torch.max(outputs, 1)\n",
    "        accuracy = (labels == argmax).float().mean()\n",
    "        train_acc.append(accuracy)\n",
    "            \n",
    "    print(f\"Train Loss: {np.mean(train_losses):.4f}, Train Acc: {np.mean(train_acc):.4f}\")\n",
    "    return np.mean(train_losses), np.mean(train_acc)\n",
    "\n",
    "# Validation function\n",
    "def validate(model, criterion):\n",
    "    model.eval()\n",
    "    \n",
    "    val_losses = []\n",
    "    val_acc = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_losses.append(loss.item())\n",
    "            \n",
    "            # Compute accuracy\n",
    "            _, argmax = torch.max(outputs, 1)\n",
    "            accuracy = (labels == argmax).float().mean()\n",
    "            val_acc.append(accuracy)\n",
    "                \n",
    "                \n",
    "    print(f\"Val Loss: {np.mean(val_losses):.4f}, Val Acc: {np.mean(val_acc):.4f}\")\n",
    "    return np.mean(val_losses), np.mean(val_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/25 [00:00<?, ?batch/s]\n",
      "/opt/conda/conda-bld/pytorch_1702400410390/work/aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [1,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "/opt/conda/conda-bld/pytorch_1702400410390/work/aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [4,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "/opt/conda/conda-bld/pytorch_1702400410390/work/aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [12,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "/opt/conda/conda-bld/pytorch_1702400410390/work/aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [13,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "/opt/conda/conda-bld/pytorch_1702400410390/work/aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [14,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "/opt/conda/conda-bld/pytorch_1702400410390/work/aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [15,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "/opt/conda/conda-bld/pytorch_1702400410390/work/aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [18,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "/opt/conda/conda-bld/pytorch_1702400410390/work/aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [21,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "/opt/conda/conda-bld/pytorch_1702400410390/work/aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [23,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "/opt/conda/conda-bld/pytorch_1702400410390/work/aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [30,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "/opt/conda/conda-bld/pytorch_1702400410390/work/aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [31,0,0] Assertion `t >= 0 && t < n_classes` failed.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 9\u001b[0m     train_loss, train_accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m     val_loss, val_accuracy \u001b[38;5;241m=\u001b[39m validate(model, criterion)\n\u001b[1;32m     11\u001b[0m     train_losses\u001b[38;5;241m.\u001b[39mappend(train_loss)\n",
      "Cell \u001b[0;32mIn[5], line 21\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, criterion, optimizer)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Calculate softmax and accuracy\u001b[39;00m\n\u001b[1;32m     20\u001b[0m soft_output \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39msoftmax(output, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 21\u001b[0m _, predicted \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43msoft_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m correct \u001b[38;5;241m=\u001b[39m (predicted \u001b[38;5;241m==\u001b[39m label)\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     23\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m correct \u001b[38;5;241m/\u001b[39m label\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "train_acc = []\n",
    "val_acc = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch+1} of {num_epochs}\")\n",
    "    train_loss, train_accuracy = train(model, criterion, optimizer)\n",
    "    val_loss, val_accuracy = validate(model, criterion)\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    train_acc.append(train_accuracy)\n",
    "    val_acc.append(val_accuracy)\n",
    "    scheduler.step()\n",
    "   \n",
    "torch.save(model.state_dict(), \"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "326203481c444b8ba96f16ace0090493",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 1.3930\n",
      "Train Accuracy: 28.56%\n",
      "Validation Accuracy: 32.12%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6931fe96c1f14b2b8f41f3acab748505",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Loss: 1.3172\n",
      "Train Accuracy: 35.34%\n",
      "Validation Accuracy: 39.50%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adc591c4a5ab4015ac364b0466a285e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Loss: 1.2788\n",
      "Train Accuracy: 39.88%\n",
      "Validation Accuracy: 41.50%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4861171968049c4b6ee4105e5707b3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Loss: 1.2750\n",
      "Train Accuracy: 40.78%\n",
      "Validation Accuracy: 45.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab2c0911770447f0b33790aa4ceae6b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Loss: 1.2421\n",
      "Train Accuracy: 42.78%\n",
      "Validation Accuracy: 46.88%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fdbe10c9fdf4f99b70605e1f2d0b1a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Loss: 1.2194\n",
      "Train Accuracy: 44.00%\n",
      "Validation Accuracy: 50.50%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5ba4d55af434c6099d0cfc7518a2de7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Loss: 1.2052\n",
      "Train Accuracy: 45.62%\n",
      "Validation Accuracy: 48.38%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9256e078d9f34601a677f225ecb49fc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Loss: 1.1977\n",
      "Train Accuracy: 45.81%\n",
      "Validation Accuracy: 49.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5eac06ee96a54778ae72ea1e83d16aff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, Loss: 1.1712\n",
      "Train Accuracy: 46.91%\n",
      "Validation Accuracy: 54.25%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9dd0a3c40fb4744bf46a4b8ad629895",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Loss: 1.1616\n",
      "Train Accuracy: 48.28%\n",
      "Validation Accuracy: 53.62%\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, Subset\n",
    "from torchvision import transforms, models\n",
    "import torch.optim as optim\n",
    "import tqdm\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from LeNet2 import *\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
    "        self.img_labels = pd.read_csv(annotations_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = f\"{self.img_dir}/{self.img_labels.iloc[idx, 0]}.jpg\"\n",
    "        image = Image.open(img_path)\n",
    "        #image = read_image(img_path)\n",
    "        label = self.img_labels.iloc[idx, 1] - 1\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label \n",
    "\n",
    "# Lire le fichier CSV\n",
    "csv_file = 'train.csv'\n",
    "labels_df = pd.read_csv(csv_file)\n",
    "\n",
    "# Dataset personnalisé\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        self.labels_df = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.root_dir, self.labels_df.iloc[idx, 0])\n",
    "        image = Image.open(img_name)\n",
    "        label = self.labels_df.iloc[idx, 1]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "# Définir les transformations\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    # MODIF : J'ai modifié 224 en 256 dans le Resize\n",
    "    # MODIF : Et j'ai finalement changé le Resize en CenterCrop\n",
    "    # transforms.Resize((256, 256)),\n",
    "    transforms.CenterCrop(256),\n",
    "    # AJOUT DATA AUGMENTATION (Pour AlexNet, pas testé sur LeNet)\n",
    "    transforms.RandomRotation(degrees=90),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    # FIN DATA AUGMENTATION\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(0.5,0.5)\n",
    "])\n",
    "\n",
    "# Charger le dataset complet\n",
    "# MODIF : J'ai commenté la ligne ci-dessous pour mettre un CustomImageDataset \n",
    "# dataset = CustomDataset(csv_file=csv_file, root_dir='train/train', transform=data_transforms)\n",
    "dataset = CustomImageDataset(annotations_file='train.csv', img_dir='train', transform=data_transforms)\n",
    "\n",
    "# Séparer le dataset en train et validation\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "# MODIF : J'ai commenté la ligne ci-dessous pour mettre un Subset\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "#train_dataset = Subset(dataset, range(train_size))\n",
    "#val_dataset = Subset(dataset, range(train_size, train_size+val_size))\n",
    "\n",
    "# Créer des DataLoader pour les ensembles d'entraînement et de validation\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "# Définir le modèle (utilisation d'un modèle pré-entraîné pour un transfert d'apprentissage)\n",
    "# MODIF : 3 lignes ci-dessous commentées pour mettre mon propre modèle\n",
    "#model = models.resnet18(pretrained=True)\n",
    "#num_ftrs = model.fc.in_features\n",
    "#model.fc = nn.Linear(num_ftrs, 4)  # Adapter la dernière couche au nombre de classes (ici 4 classes)\n",
    "#model = LeNet()\n",
    "model = LeNet2()\n",
    "\n",
    "# Définir la fonction de perte et l'optimiseur\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "# Entraîner le modèle\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0 # AJOUT\n",
    "    total = 0   # AJOUT\n",
    "    for inputs, labels in tqdm(train_loader):\n",
    "        #print(inputs[0])\n",
    "        #print(inputs[1])\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        # MODIF : J'avais ajouté les deux lignes suivantes pour voir les sorties (qui étaient toutes identiques pour un batch donnée avec\n",
    "        # la fonction sigmoïde, j'ai donc remplacé par des ReLu)\n",
    "        #print(outputs[0]) \n",
    "        #print(outputs[16])\n",
    "        # AJOUT : calcul de la train accuracy\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        # FIN AJOUT\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "    \n",
    "    \n",
    "    epoch_loss = running_loss / train_size\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}')\n",
    "\n",
    "    print(f'Train Accuracy: {100 * correct / total:.2f}%')\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f'Validation Accuracy: {100 * correct / total:.2f}%')\n",
    "\n",
    "print('Training complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
